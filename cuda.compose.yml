services:
  app:
    build:
      context: .
      dockerfile: deploy/cuda.Dockerfile
      platform: linux/amd64
    image: "transcription-bot"
    volumes:
      - ../storage:/app/storage
      - models:/models
    env_file: "compose.env"
    command: "npm run start"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    develop:
      watch:
        - action: sync
          path: .
          target: /app
volumes:
  models:
    external: true
